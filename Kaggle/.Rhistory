NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
setwd("~/Development/learning/edx/15.071x-The-Analytics-Edge/Kaggle")
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
library(tm)
library(SnowballC)
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, tolower)
CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
CorpusAbstract = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusAbstract = tm_map(CorpusAbstract, tolower)
CorpusAbstract = tm_map(CorpusAbstract, PlainTextDocument)
CorpusAbstract = tm_map(CorpusAbstract, removePunctuation)
CorpusAbstract = tm_map(CorpusAbstract, removeWords, stopwords("english"))
CorpusAbstract = tm_map(CorpusAbstract, stemDocument)
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
Headline = as.data.frame(as.matrix(dtmHeadline))
colnames(Headline) = make.names(colnames(Headline))
colnames(Headline) = paste("H", colnames(Headline))
colnames(Headline) = make.names(colnames(Headline))
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
Snippet = as.data.frame(as.matrix(dtmSnippet))
colnames(Snippet) = make.names(colnames(Snippet))
colnames(Snippet) = paste("S", colnames(Snippet))
colnames(Snippet) = make.names(colnames(Snippet))
dtmAbstract = DocumentTermMatrix(CorpusAbstract)
dtmAbstract = DocumentTermMatrix(CorpusAbstract)
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
library(tm)
library(SnowballC)
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, tolower)
CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
CorpusAbstract = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusAbstract = tm_map(CorpusAbstract, tolower)
CorpusAbstract = tm_map(CorpusAbstract, PlainTextDocument)
CorpusAbstract = tm_map(CorpusAbstract, removePunctuation)
CorpusAbstract = tm_map(CorpusAbstract, removeWords, stopwords("english"))
CorpusAbstract = tm_map(CorpusAbstract, stemDocument)
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
library(tm)
library(SnowballC)
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, tolower, lazy=T)
CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument, lazy=T)
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation, lazy=T)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"), lazy=T)
CorpusHeadline = tm_map(CorpusHeadline, stemDocument, lazy=T)
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusSnippet = tm_map(CorpusSnippet, tolower, lazy=T)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument, lazy=T)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation, lazy=T)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"), lazy=T)
CorpusSnippet = tm_map(CorpusSnippet, stemDocument, lazy=T)
CorpusAbstract = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusAbstract = tm_map(CorpusAbstract, tolower, lazy=T)
CorpusAbstract = tm_map(CorpusAbstract, PlainTextDocument, lazy=T)
CorpusAbstract = tm_map(CorpusAbstract, removePunctuation, lazy=T)
CorpusAbstract = tm_map(CorpusAbstract, removeWords, stopwords("english"), lazy=T)
CorpusAbstract = tm_map(CorpusAbstract, stemDocument, lazy=T)
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
library(tm)
library(SnowballC)
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, tolower)
CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
dtmHeadline = removeSparseTerms(dtmHeadline, 0.99)
Headline = as.data.frame(as.matrix(dtmHeadline))
colnames(Headline) = make.names(colnames(Headline))
colnames(Headline) = paste("H", colnames(Headline))
colnames(Headline) = make.names(colnames(Headline))
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
dtmSnippet = removeSparseTerms(dtmSnippet, 0.99)
Snippet = as.data.frame(as.matrix(dtmSnippet))
colnames(Snippet) = make.names(colnames(Snippet))
colnames(Snippet) = paste("S", colnames(Snippet))
colnames(Snippet) = make.names(colnames(Snippet))
news = cbind(Headline, Snippet)
news$NewsDesk = as.factor(c(NewsTrain$NewsDesk, NewsTest$NewsDesk))
news$SectionName = as.factor(c(NewsTrain$SectionName, NewsTest$SectionName))
news$SubsectionName = as.factor(c(NewsTrain$SubsectionName, NewsTest$SubsectionName))
news$WordCount = c(NewsTrain$WordCount, NewsTest$WordCount)
news$Weekday = c(strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S"), strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S"))$wday
news$Month = c(strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S"), strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S"))$mon
news$UniqueID = c(NewsTrain$UniqueID, NewsTest$UniqueID)
Train = head(news, nrow(NewsTrain))
NewsTest = tail(news, nrow(NewsTest))
Train$Popular = NewsTrain$Popular
NewsTrain = Train
library(arm)
logModel = bayesglm(Popular ~ . -UniqueID, data = NewsTrain, family = "binomial")
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
Headline = as.data.frame(as.matrix(dtmHeadline))
colnames(Headline) = make.names(colnames(Headline))
colnames(Headline) = paste("H", colnames(Headline))
colnames(Headline) = make.names(colnames(Headline))
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
Snippet = as.data.frame(as.matrix(dtmSnippet))
colnames(Snippet) = make.names(colnames(Snippet))
colnames(Snippet) = paste("S", colnames(Snippet))
colnames(Snippet) = make.names(colnames(Snippet))
news = cbind(Headline, Snippet)
news$NewsDesk = as.factor(c(NewsTrain$NewsDesk, NewsTest$NewsDesk))
news$SectionName = as.factor(c(NewsTrain$SectionName, NewsTest$SectionName))
news$SubsectionName = as.factor(c(NewsTrain$SubsectionName, NewsTest$SubsectionName))
news$WordCount = c(NewsTrain$WordCount, NewsTest$WordCount)
news$Weekday = c(strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S"), strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S"))$wday
news$Month = c(strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S"), strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S"))$mon
news$Weekday = c(strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S"), strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S"))$wday
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
library(tm)
library(SnowballC)
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, tolower)
CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
dtmHeadline = removeSparseTerms(dtmHeadline, 0.99)
Headline = as.data.frame(as.matrix(dtmHeadline))
colnames(Headline) = make.names(colnames(Headline))
colnames(Headline) = paste("H", colnames(Headline))
colnames(Headline) = make.names(colnames(Headline))
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
dtmSnippet = removeSparseTerms(dtmSnippet, 0.99)
Snippet = as.data.frame(as.matrix(dtmSnippet))
colnames(Snippet) = make.names(colnames(Snippet))
colnames(Snippet) = paste("S", colnames(Snippet))
colnames(Snippet) = make.names(colnames(Snippet))
news = cbind(Headline, Snippet)
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
library(tm)
library(SnowballC)
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
library(tm)
library(SnowballC)
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, tolower)
CorpusHeadline = tm_map(CorpusHeadline, tolower)
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, tolower)
CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
dtmHeadline = DocumentTermMatrix(CorpusHeadline)
dtmHeadline = removeSparseTerms(dtmHeadline, 0.99)
Headline = as.data.frame(as.matrix(dtmHeadline))
colnames(Headline) = make.names(colnames(Headline))
news = cbind(Headline)
news$NewsDesk = as.factor(c(NewsTrain$NewsDesk, NewsTest$NewsDesk))
news$SectionName = as.factor(c(NewsTrain$SectionName, NewsTest$SectionName))
news$SubsectionName = as.factor(c(NewsTrain$SubsectionName, NewsTest$SubsectionName))
news$WordCount = c(NewsTrain$WordCount, NewsTest$WordCount)
news$Weekday = c(strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S"), strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S"))$wday
hist(subset(NewsTrain, Popular == 1)$Month)
news$Month = c(strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S"), strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S"))$mon
hist(subset(news, Popular == 1)$Month)
news$UniqueID = c(NewsTrain$UniqueID, NewsTest$UniqueID)
Train = head(news, nrow(NewsTrain))
NewsTest = tail(news, nrow(NewsTest))
Train$Popular = NewsTrain$Popular
NewsTrain = Train
hist(subset(news, Popular == 1)$Month)
hist(subset(NewsTrain, Popular == 1)$Month)
hist(subset(NewsTrain, Popular == 1)$Weekday)
hist(subset(NewsTrain, Popular == 1)$SectionName)
cor(subset(NewsTrain, Popular == 1))
library(arm)
logModel = bayesglm(Popular ~ . -UniqueID, data = NewsTrain, family = "binomial")
predictLog = predict(logModel, newdata = NewsTest)
predictLog
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = predictLog)
write.csv(MySubmission, "final4.csv", row.names=FALSE)
summary(logModel)
logModel = bayesglm(Popular ~ can + get + morn + new + read + today + word + NewsDesk, data = NewsTrain, family = "binomial")
library(caTools)
spl = sample.split(NewsTrain$Popular, SplitRatio = 0.7)
train = subset(NewsTrain, spl == TRUE)
test = subset(NewsTrain, spl == FALSE)
table(test$Popular)
1632 / (1632 + 328)
logModel = bayesglm(Popular ~ can + get + morn + new + read + today + word + NewsDesk + SectionName + SubsectionName + WordCount + Weekday, data = train, family = "binomial")
predictLog = predict(logModel, newdata = test, type = "response")
table(test$Popular, predictLog)
table(test$Popular, predictLog >= 0.5)
(1568 + 212) / (1568 + 212 + 64 + 116)
library(ROCR)
predROCR = prediction(predictLog, test$Popular)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR)
plot(perfROCR, colorize = TRUE)
auc = as.numeric(performance(predROCR, "auc")@y.values)
auc
summary(logModel)
summary(logModel)
logModel = bayesglm(Popular ~ get + morn + read + today + word + NewsDesk + SectionName + SubsectionName + WordCount + Weekday, data = train, family = "binomial")
summary(logModel)
predictLog = predict(logModel, newdata = test, type = "response")
table(test$Popular, predictLog >= 0.5)
predROCR = prediction(predictLog, test$Popular)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize = TRUE)
auc = as.numeric(performance(predROCR, "auc")@y.values)
logModel = bayesglm(Popular ~ get + morn + read + today + word + NewsDesk + SectionName + SubsectionName + WordCount + Weekday, data = NewsTrain, family = "binomial")
predictLog = predict(logModel, newdata = NewsTest, type = "response")
summary(logModel)
min(predictLog)
range(predictLog)
range(predictLog >= 0.5)
sum(predictLog >= 0.5)
predictLog = predict(logModel, newdata = NewsTest, type = "response")
head(predictLog)
sum(predictLog >= 0.5)
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = predictLog)
write.csv(MySubmission, "final4.csv", row.names=FALSE)
predROCR = prediction(predictLog >= 0.2, test$Popular)
