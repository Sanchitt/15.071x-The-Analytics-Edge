sparse
tweets = read.csv("tweets.csv", stringsAsFactor = FALSE)
tweets$Negative = as.factor(tweets$Avg <= -1)
library(tm)
library(SnowballC)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
frequencies = DocumentTermMatrix(corpus)
inspect(frequencies[1000:1005, 505:515])
findFreqTerms(frequencies, lowfreq = 100)
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
findFreqTerms(frequencies, lowfreq = 100)
sparse = removeSparseTerms(frequencies, 0.995)
sparse
tweetSparse = as.data.frame(as.matrix(sparse))
colnames(tweetSparse) = make.names(colnames(tweetSparse))
View(tweetSparse)
tweetSparse$Negative = tweets$Negative
library(caTools)
set.seed(!23)
split = sample.split(tweetSparse$Negative, SplitRatio = 0.7)
train = subset(tweetSparse, split == TRUE)
test = subset(tweetSparse, split == FALSE)
library(rpart)
library(rpart.plot)
CART = rpart(Negative ~ ., data = train, method = "class")
prp(CART)
set.seed(!23)
split = sample.split(tweetSparse$Negative, SplitRatio = 0.7)
train = subset(tweetSparse, split == TRUE)
test = subset(tweetSparse, split == FALSE)
library(rpart)
library(rpart.plot)
CART = rpart(Negative ~ ., data = train, method = "class")
prp(CART)
predictCART = predict(CART, newdata= test, type = "class")
table(test$Negative, predictCART)
(293 + 23) / (293 + 23 + 32 + 7)
table(test$Negative)
library(randomForest)
set.seed(!23)
RF= randomForest(Negative ~ ., data = train)
predictRF = predict(RF, newdata = test)
table(test$Negative, predictRF)
(296 + 24) / (296 + 24 + 4 + 31)
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
str(tweets)
tweets$Negative = as.factor(tweets$Avg <= -1)
table(tweets$Negative)
library(tm)
library(SnowballC)
corpus = Corpus(VectorSource(tweets$Tweet))
# Look at corpus
corpus
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.995)
tweetsSparse = as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) = make.names(colnames(tweetsSparse))
tweetsSparse$Negative = tweets$Negative
library(caTools)
set.seed(123)
split = sample.split(tweetsSparse$Negative, SplitRatio = 0.7)
trainSparse = subset(tweetsSparse, split==TRUE)
testSparse = subset(tweetsSparse, split==FALSE)
library(rpart)
library(rpart.plot)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
prp(tweetCART)
predictCART = predict(tweetCART, newdata=testSparse, type="class")
table(testSparse$Negative, predictCART)
library(randomForest)
set.seed(123)
predictRF = predict(tweetRF, newdata=testSparse)
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
str(tweets)
# Create dependent variable
tweets$Negative = as.factor(tweets$Avg <= -1)
table(tweets$Negative)
# Install new packages
install.packages("tm")
install.packages("SnowballC")
tweets = read.csv("tweets.csv", stringsAsFactor = FALSE)
tweets$Negative = as.factor(tweets$Avg <= -1)
library(tm)
library(SnowballC)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
sparse = removeSparseTerms(frequencies, 0.995)
tweetSparse = as.data.frame(as.matrix(sparse))
colnames(tweetSparse) = make.names(colnames(tweetSparse))
tweetSparse$Negative = tweets$Negative
library(caTools)
set.seed(123)
split = sample.split(tweetSparse$Negative, SplitRatio = 0.7)
train = subset(tweetSparse, split == TRUE)
test = subset(tweetSparse, split == FALSE)
library(rpart)
library(rpart.plot)
CART = rpart(Negative ~ ., data = train, method = "class")
prp(CART)
predictCART = predict(CART, newdata= test, type = "class")
table(test$Negative, predictCART)
(294 + 18) / (294 + 18 + 37 + 6)
table(test$Negative)
library(randomForest)
set.seed(123)
RF= randomForest(Negative ~ ., data = train)
predRF = predict(randomForest, newdata = test)
predRF = predict(randomForest, newdata = test)
RF= randomForest(Negative ~ ., data = train)
predictRF = predict(RF, newdata = test
)
table(test$Negative, predictRF)
(292 + 23) / (292 + 23 + 32 + 8)
tweetLM = lm(Negative ~ ., data = train)
predictLM = predict(tweetLM, newdata = test)
table(test$Negative, predictLM >= 0.5)
(1 + 54) / (1 + 54 + 1 + 299)
tweetLM = glm(Negative ~ ., data = train, family = binomial)
predictLM = predict(tweetLM, newdata = test)
table(test$Negative, predictLM >= 0.5)
(253 + 28) / (253 + 528 + 27 + 47)
predictLM = predict(tweetLM, newdata = test, type = "response")
table(test$Negative, predictLM >= 0.5)
(253 + 28) / (253 + 28 + 27 + 47)
emails = read.csv("energy_bids.csv", stringAsFactors = FALSE)
emails = read.csv("energy_bids.csv", stringsAsFactors = FALSE)
str(emails)
emails$email[1]
strwrap(emails$email[2])
table(emails$responsive)
library(tm)
corpus = Corpus(VectorSource(emails$email))
corpus[[1]]
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
corpus[[1]]
dtm = DocumentTermMatrix(corpus)
dtm
dtm = removeSparseTerms(dtm, 0.97)
dtm
labeledterms = as.data.frame(as.matrix(dtm))
labeledterms$responsive = emails$responsive
str(labeledterms)
library(caTools)
set.speed(144)
set.seed(144)
spl = sample.split(labeledterms$responsive, SplitRatio = 0.7)
train = subset(labeledterms, spl == TRUE)
test = subset(labeledterms, spl == FALSE)
library(rpart)
library(rpart.plot)
emailCART = rpart(responsive ~ ., data = train, method = "class")
prp(emailCART)
predCART = predict(emailCART, newdata = test)
predCART = predict(emailCART, newdata = test, type = "response")
predCART = predict(emailCART, newdata = test, type = "class")
table(test$responsive, predCART)
(195 + 25) / (195 + 25 + 17 + 20)
table(test$responsive)
(215) / (215 + 42)
library(ROCR
)
predROCR = prediction(predCART, test$responsive)
predCART
predCART = predict(emailCART, newdata = test)
pred.prob = predCART[,2]
table(test$responsive, pred.prob)
table(test$responsive, pred.prob >= 0.5)
predROCR = prediction(pred.prob, test$responsive)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR)
plot(perfROCR, colorize = TRUE)
auc = performance(predROCR, "auc")@y.values
auc = as.numeric(performance(predROCR, "auc")@y.values)
auc
setwd("~/Development/learning/edx/15.071x-The-Analytics-Edge/Unit-5/Assignment")
wiki = read.csv("wiki.csv", stringsAsFactor = FALSE)
wiki$Vandal = as.factor(wiki$Vandal)
str(wiki)
sum(wiki$Vandal)
table(wiki$Vandal)
library(tm)
corpusAdded = Corpus(VectorSource(wiki$Added))
corpusAdded = tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded = tm_map(corpusAdded, stemDocument)
dtmAdded = DocumentTermMatrix(corpusAdded)
length(stopwords("english"))
str(dtmAdded)
dtmAdded
sparseAdded = removeSparseTerms(dtmAdded, 0.97)
sparseAdded
dtmAdded
removeSparseTerms(dtmAdded, 0.97)
removeSparseTerms(dtmAdded, 0.99997)
removeSparseTerms(dtmAdded, 99.997)
removeSparseTerms(dtmAdded, .99997)
removeSparseTerms(dtmAdded, .7)
removeSparseTerms(dtmAdded, .997)
wordsAdded = as.data.frame(as.matrix(sparseAdded))
colnames(wordsAdded) = paste('A', colnames(wordsAdded))
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
wordsAdded = as.data.frame(as.matrix(sparseAdded))
View(wordsAdded)
sparseAdded = removeSparseTerms(dtmAdded, .997)
sparseAdded
wordsAdded = as.data.frame(as.matrix(sparseAdded))
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
corpusRemoved = Corpus(VectorSource(wiki$Removed))
corpusRemoved = tm_map(corpusRemoved, removeWords, stopwords("english"))
corpusRemoved = tm_map(corpusRemoved, stemDocument)
dtmRemoved = DocumentTermMatrix(corpusRemoved)
sparseRemoved = removeSparseTerms(dtmRemoved, 0.997)
wordsRemoved = as.data.frame(as.matrix(sparseRemoved))
colnames(wordsRemoved) = paste("A", colnames(wordsRemoved))
wordsRemoved
str(wordsRemoved)
wikiWords = cbind(wordsAdded, wordsRemoved)
wikiWords$Vandal = wiki$Vandal
table(wikiWords$Vandal)
2061 / (2061 + 1815)
library(rpart)
library(rpart.plot)
library(caTools)
set.seed(123)
spl = sample.split(wikiWords$Vandal, SplitRatio = 0.7)
train = subset(wikiWords, spl == TRUE)
test = subset(wikiWords, spl == FALSE)
wikiCART = rpart(Vandal ~ ., data = train, method = "class")
prp(wikiCART)
predCART = predict(wikiCART, newdata = test)
predCART.prob = predCART[,2]
table(test$Vandal, predCART.prob >= 0.5)
(618 + 12) / (618 + 12 + 533)
wikiWords2 = wikiWords
wikiWords2$HTTP = ifelse(grepl("http", wiki$Added, fixed = TRUE))
wikiWords2$HTTP = ifelse(grepl("http", wiki$Added, fixed = TRUE), 1, 0)
sum(wikiWords2$HTTP)
train2 = subset(wikiWords2, spl == TRUE)
test2 = subset(wikiWords2, spl == FALSE)
wikiCART2 = rpart(Vandal ~ ., data = train2, method = "class")
prp(wikiCART2)
predCART2 = predict(wikiCART2, newdata = test2)
predCART2.prob = predCART2[,2]
table(test$Vandal, predCART2.prob >= 0.5)
(609 + 57) / (609 + 57 + 9 + 488)
wikiWords2$NumWordsAdded = rowSums(as.matrix(dtmAdded))
wikiWords2$NumWordsRemoved = rowSums(as.matrix(dtmRemoved))
wikiWords2$NumWordsAdded
wikiWords2$NumWordsAdded / nrow(wikiWords2)
sum(wikiWords2$NumWordsAdded) / nrow(wikiWords2)
train3 = subset(wikiWords2, spl == TRUE)
test3 = subset(wikiWords2, spl == FALSE)
wikiCART3 = rpart(Vandal ~ ., data = train3, method = "class")
prp(wikiCART3)
predCART3 = predict(wikiCART3, newdata = test3)
predCART3.prob = predCART3[,2]
table(test$Vandal, predCART3.prob >= 0.5)
(514 + 248) / (514 + 248 + 297 + 104)
wikiWords3 = wikiWords2
wikiWords3$Minor = wiki$Minor
wikiWords3$Loggedin = wiki$Loggedin
train4 = subset(wikiWords3, spl == TRUE)
test4 = subset(wikiWords3, spl == FALSE)
wikiCART4 = rpart(Vandal ~ ., data = train4, method = "class")
prp(wikiCART4)
predCART4 = predict(wikiCART4, newdata = test4)
predCART4.prob = predCART4[,2]
table(test$Vandal, predCART4.prob >= 0.5)
(595 + 241) / (595 + 241 + 23 + 304)
trials = read.csv("clinical_trial.csv", stringsAsFactors = FALSE)
str(trials)
summary(trials)
trials = read.csv("clinical_trial.csv", stringsAsFactors = FALSE)
str(trials)
summary(trials)
max(nchar(trials$abstract))
sum(nchar(trials$abstract) == 0)
which(min(nchar(trials$title)))
min(nchar(trials$title))
which(nchar(trials$title) == 28)
trials$title[1258]
library(tm)
corpusTitle = Corpus(VectorSource(trials$title))
corpusAbstract = Corpus(VectorSource(trials$abstract))
corpusTitle = tm_map(corpusTitle, tolower)
corpusTitle = tm_map(corpusTitle, PlainTextDocument)
corpusAbstract = tm_map(corpusAbstract, tolower)
corpusAbstract = tm_map(corpusAbstract, PlainTextDocument)
corpusTitle = tm_map(corpusTitle, removePunctuation)
corpusAbstract = tm_map(corpusAbstract, removePunctuation)
corpusTitle = tm_map(corpusTitle, removeWords, stopwords("english"))
corpusAbstract = tm_map(corpusAbstract, removeWords, stopwords("english"))
corpusTitle = tm_map(corpusTitle, stemDocument)
corpusAbstract = tm_map(corpusAbstract, stemDocument)
dtmTitle = DocumentTermMatrix(corpusTitle)
dtmAbstract = DocumentTermMatrix(corpusAbstract)
dtmTitle = removeSparseTerms(dtmTitle, 0.95)
dtmAbstract = removeSparseTerms(dtmAbstract, 0.95)
dtmTitle = as.data.frame(as.matrix(dtmTitle))
dtmAbstract = as.data.frame(as.matrix(dtmAbstract))
str(dtmTitle)
str(dtmAbstract)
View(dtmTitle)
max(colSums(dtmTitle))
max(colSums(dtmAbstract))
which(colSums(dtmAbstract) == 8381)
colnames(dtmTitle) = paste0("T", colnames(dtmTitle))
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
dtm = cind(dtmTitle, dtmAbstract)
dtm = cbind(dtmTitle, dtmAbstract)
View(dtmTitle)
View(trials)
dtm$trial = trials$trial
str(dtm)
library(caTools)
set.seed(144)
spl = sample.split(dtm$trial, SplitRatio = 0.7)
train = subset(dtm, spl == TRUE)
test = subset(dtm, spl == FALSE)
table(dtm$trial)
1043 / (1043 + 817)
library(rpart)
library(rpart.plot)
trialCART = rpart(trial ~ ., data = train, method = "class")
prp(trialCART)
predCARTTrain = predict(trialCART)
table(test$trial, trialCART >= 0.5)
table(test$trial, predCARTTrain >= 0.5)
table(train$trial, predCARTTrain >= 0.5)
predCARTTrain.pred = predCARTTrain[,2]
table(train$trial, predCARTTrain.pred >= 0.5)
(631 + 441) / (631 + 441 + 99 + 131)
max(predCARTTrain.pred)
441 / (441 + 131)
99 / (99 + 631)
631 / (99 + 631)
predCARTTest = predict(trialCART, newdata = test)
predCARTTest.pred = predCARTTest[,2]
table(test$trial, predCARTTest.pred >= 0.5)
(261 + 162) / (261 + 162 + 52 + 83)
library(ROCR)
predROCR = prediction(test$trial, predCARTTest.pred >= 0.5)
auc = as.numeric(performance(predROCR, "auc")@y.values)
auc
predROCR = prediction(test$trial, predCARTTest.pred)
auc = as.numeric(performance(predROCR, "auc")@y.values)
predROCR = prediction(test$trial, predCARTTest)
predROCR = prediction(predCARTTest.pred, test$trial)
auc = as.numeric(performance(predROCR, "auc")@y.values)
auc
emails = read.csv("emails.csv", stringsAsFactors = FALSE)
sum(emails$spam)
str(emails)
max(nchar(emails$text))
which.min(nchar(emails$text))
library(tm)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames = make.names(emailsSparse)
which.max(colSums(emailsSparse))
emailsSparse$spam = emails$spam
findFreqTerms(spdtm, lowfreq = 5000)
spdtm
findFreqTerms(emailsSparse, lowfreq = 5000)
View(emailsSparse)
emailsSparse$spam = emails$spam
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames(emailsSparse) = make.names(emailsSparse)
which.max(colSums(emailsSparse))
emailsSparse$spam = emails$spam
dtm = DocumentTermMatrix(corpus)
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
View(emailsSparse)
colnames(emailsSparse) = make.names(colnames(emailsSparse))
which.max(colSums(emailsSparse))
emailsSparse$spam = emails$spam
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames(emailsSparse) = make.names(colnames(emailsSparse))
emailsSparse$spam = emails$spam
View(emailsSparse)
subset(emailsSparse$spam == 0)
sort(colSums(subset(emailsSparse, spam == 0)))
rev(sort(colSums(subset(emailsSparse, spam == 0))))
rev(sort(colSums(subset(emailsSparse, spam == 1))))
colSums(subset(emailsSparse, spam == 1)) >= 1000
sum(colSums(subset(emailsSparse, spam == 1)) >= 1000)
?sort
colSums(subset(emailsSparse, spam == 1))
sort(colSums(subset(emailsSparse, spam == 1)))
emailsSparse$spam = as.factor(emailsSparse$spam)
set.seed(123)
library(caTools)
set.seed(123)
spl == sample.split(emailsSparse$spam, SplitRatio = 0.7)
train = subset(emailsSparse, spl == TRUE)
spl = sample.split(emailsSparse$spam, SplitRatio = 0.7)
train = subset(emailsSparse, spl == TRUE)
test = subset(emailsSparse, spl == FALSE)
spamLog = glm(spam ~ ., data = train, family = binomial)
library(rpart)
library(rpart.plot)
spamCART = rpart(spam ~ ., data = train, method = "class")
library(randomForest)
spamRF = randomForest(spam ~ ., data = train)
set.seed(123)
spamRF = randomForest(spam ~ ., data = train)
predLog = predict(spamLog, newdata = test)
predLog.prob = predLog[,2]
sum(predLog.prob <  0.00001)
predLog = predict(spamLog, newdata = test)
predLog
sum(predLog <  0.00001)
predLog = predict(spamLog)
sum(predLog <  0.00001)
sum(predLog > 0.99999)
sum(predLog <=  0.00001 & predLog >= 0.99999)
summary(spamLog)
prp(spamCART)
table(train$spam, predLog >= 0.5)
(3052 + 954) / (3052 + 954 + 4)
library(ROCR)
logPredROCR = prediction(spamLog)
logPredROCR = prediction(predLog, train$spam)
auc = as.numeric(performance(logPredROCR, "auc")@y.values)
auc
predCART = predict(spamCART, type = "class")
table(train$spam, predCART)
(2885 + 894) / (2885 + 894 + 67 + 167)
predCART = predict(spamCART)
predCART.pred = predCART[,2]
table(train$spam, predCART.pred)
table(train$spam, predCART.pred >= 0.5)
predCARTROCR = prediction(spamCART, train$spam)
spam
predCARTROCR = prediction(spamCART, train$spam)
predCARTROCR = prediction(spamCART >= 0.5, train$spam)
predROCR = predict(spamCART)
predCARTROCR = prediction(predROCR, train$spam)
predCARTROCR = prediction(predROCR[,2], train$spam)
as.numeric(performance(predCARTROCR, "auc")@y.values)
predRF = predict(spamRF)
table(train$spam, predRF)
(3013 + 914) / (3013 + 914 + 44 + 39)
predRF = predict(spamRF, type = "prob")
predRFROCR = prediction(predRF, train$spam)
predRFROCR = prediction(predRF[,2], train$spam)
as.numeric(performance(predRFROCR, "auc")@y.values)
predLog = predict(spamLog, newdata = test)
table(test$spam, predLog)
table(test$spam, predLog >= 0.5)
(1258 + 376) / (1258 + 376 + 34 + 50)
logPredROCR = prediction(predLog, train$spam)
auc = as.numeric(performance(logPredROCR, "auc")@y.values)
logPredROCR = prediction(predLog, test$spam)
auc = as.numeric(performance(logPredROCR, "auc")@y.values)
auc
table(test$spam, predCART.pred >= 0.5)
predCART.pred = predCART[,2]
table(test$spam, predCART.pred >= 0.5)
predCART = predict(spamCART, newdata = test)
predCART.pred = predCART[,2]
table(test$spam, predCART.pred >= 0.5)
(1228 + 386) / (1228 + 386 + 24 + 80)
predCARTROCR = prediction(predROCR[,2], test$spam)
predROCR = prediction(predCART, test$spam)
predROCR = prediction(predCART.pred, test$spam)
predCARTROCR = prediction(predROCR[,2], test$spam)
predCARTROCR = prediction(predROCR, test$spam)
predROCR = prediction(predCART.pred, test$spam)
as.numeric(performance(predROCR, "auc")@y.values)
predRF = predict(spamRF, newdata = test, type = "prob")
predRFROCR = prediction(predRF[,2], test$spam)
as.numeric(performance(predRFROCR, "auc")@y.values)
predRF = predict(spamRF, newdata = test, type = "prob")
table(test$spam, predRF[,2] >= 0.5)
(1290 + 386) / (1290 + 386 + 24 + 18)
predROCR = predict(spamCART, newdata = test)
table(test$spam, predROCR[,2] >= 0.5)
(1228 + 386) / (1228 + 386 + 24 + 80)
